{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Peer-graded Assignment: Capstone Project - The Battle of Neighborhoods (Week 1)\n## Introduction/Business Problem\n\n*The idea of this study is to reflect the reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. If the data set is viewed it can be concluded that th data set is quite complex to ground zero the information regardng the crimes happening in a specific are or location of Chicago, which are the crimes happening more frequently compared to other ones in a specifc area, where there is a need to increse the number of police commandos,etc.*"}, {"metadata": {}, "cell_type": "markdown", "source": "## Data\n\n*This dataset reflects reported incidents of crime (with the exception of murders where data exists for each victim) that occurred in the City of Chicago from 2001 to present, minus the most recent seven days. Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system. In order to protect the privacy of crime victims, addresses are shown at the block level only and specific locations are not identified. Should you have questions about this dataset, you may contact the Research & Development Division of the Chicago Police Department at PSITAdministration@ChicagoPolice.org.*\n\n*Disclaimer: These crimes may be based upon preliminary information supplied to the Police Department by the reporting parties that have not been verified. The preliminary crime classifications may be changed at a later date based upon additional investigation and there is always the possibility of mechanical or human error. Therefore, the Chicago Police Department does not guarantee (either expressed or implied) the accuracy, completeness, timeliness, or correct sequencing of the information and the information should not be used for comparison purposes over time. The Chicago Police Department will not be responsible for any error or omission, or for the use of, or the results obtained from the use of this information. All data visualizations on maps should be considered approximate and attempts to derive specific addresses are strictly prohibited. The Chicago Police Department is not responsible for the content of any off-site pages that are referenced by or that reference this web page other than an official City of Chicago or Chicago Police Department web page.* \n\n*The user specifically acknowledges that the Chicago Police Department is not responsible for any defamatory, offensive, misleading, or illegal conduct of other users, links, or third parties and that the risk of injury from the foregoing rests entirely with the user. The unauthorized use of the words \"Chicago Police Department,\" \"Chicago Police,\" or any colorable imitation of these words or the unauthorized use of the Chicago Police Department logo is unlawful. This web page does not, in any way, authorize such use. Data are updated daily. To access a list of Chicago Police Department - Illinois Uniform Crime Reporting (IUCR) codes, go to http://data.cityofchicago.org/Public-Safety/Chicago-Police-Department-Illinois-Uniform-Crime-R/c7ck-438e*\n\n*To provide the people the necessary information, I'll be combining Chicago Crime Data's 2001 to present data that contains Case Number, ID, Date District,etc.*"}, {"metadata": {}, "cell_type": "markdown", "source": "## Formal Code with Output\nImporting the needed libraries"}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\n%matplotlib inline \n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\n\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfont = {'size'   : 12}\nmpl.rc('font', **font)\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, cross_val_score\n\ndef cross_validate(model, n_splits = 10):\n    \n    k_fold = KFold(n_splits = n_splits)\n    scores = [model.fit(X[train], y[train]).score(X[test], y[test]) for train, test in k_fold.split(X)]\n    \n    scores = np.percentile(scores, [40, 50, 60])\n    return scores\n\n#!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\nfrom folium.plugins import MarkerCluster\nfrom folium.plugins import FastMarkerCluster\nfrom folium import plugins\n\n# Module to convert an address into latitude and longitude values\nfrom geopy.geocoders import Nominatim \n\nprint('Libraries imported.')\n\n# Get longitude and latitude for Toronto\naddress = 'Chicago, Chicago'\n\ngeolocator = Nominatim(user_agent=\"chicago\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Rio de Janeiro is {}, {}.'.format(latitude, longitude))\n\nCLIENT_ID = 'IXOZWZIF3TQRA2C20CP4OJP3CZPRBRBBDCPC2AHRN3QVRC2F' # your Foursquare ID\nCLIENT_SECRET = 'HT1GCJXEUBRQ53R3QYEX3L5EIHZYGOVDMNMG50CNO2LHYHCU' # your Foursquare Secret\nACCESS_TOKEN = 'C0J1TLXOZWJXE4VNTKAOZBDJ3J4F1FY2YA2TM4L0YIFBTT04' # your FourSquare Access Token\nVERSION = '20180604'\nLIMIT = 30\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Libraries imported.\nThe geograpical coordinate of Rio de Janeiro is 41.8964706, -87.6357194.\nYour credentails:\nCLIENT_ID: IXOZWZIF3TQRA2C20CP4OJP3CZPRBRBBDCPC2AHRN3QVRC2F\nCLIENT_SECRET:HT1GCJXEUBRQ53R3QYEX3L5EIHZYGOVDMNMG50CNO2LHYHCU\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Loading the Dataset"}, {"metadata": {}, "cell_type": "code", "source": "csv_path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/FinalModule_Coursera/data/Chicago_Crime_Data-v2.csv'\ndf = pd.read_csv(csv_path,encoding='latin1')\nprint('Data loaded')", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Data loaded\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Size of the database"}, {"metadata": {}, "cell_type": "code", "source": "df.shape", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "(533, 22)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Details of the database"}, {"metadata": {}, "cell_type": "code", "source": "df.head()", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "         ID CASE_NUMBER                    DATE                     BLOCK  \\\n0   3512276    HK587712  08/28/2004 05:50:56 PM        047XX S KEDZIE AVE   \n1   3406613    HK456306  06/26/2004 12:40:00 PM  009XX N CENTRAL PARK AVE   \n2   8002131    HT233595  04/04/2011 05:45:00 AM        043XX S WABASH AVE   \n3   7903289    HT133522  12/30/2010 04:30:00 PM      083XX S KINGSTON AVE   \n4  10402076    HZ138551  02/02/2016 07:30:00 PM           033XX W 66TH ST   \n\n  IUCR PRIMARY_TYPE                    DESCRIPTION  \\\n0  890        THEFT                  FROM BUILDING   \n1  820        THEFT                 $500 AND UNDER   \n2  820        THEFT                 $500 AND UNDER   \n3  840        THEFT  FINANCIAL ID THEFT: OVER $300   \n4  820        THEFT                 $500 AND UNDER   \n\n           LOCATION_DESCRIPTION  ARREST  DOMESTIC  BEAT  DISTRICT  WARD  \\\n0            SMALL RETAIL STORE   False     False   911         9  14.0   \n1                         OTHER   False     False  1112        11  27.0   \n2  NURSING HOME/RETIREMENT HOME   False     False   221         2   3.0   \n3                     RESIDENCE   False     False   423         4   7.0   \n4                         ALLEY   False     False   831         8  15.0   \n\n   COMMUNITY_AREA_NUMBER FBICODE  X_COORDINATE  Y_COORDINATE  YEAR  \\\n0                   58.0       6     1155838.0     1873050.0  2004   \n1                   23.0       6     1152206.0     1906127.0  2004   \n2                   38.0       6     1177436.0     1876313.0  2011   \n3                   46.0       6     1194622.0     1850125.0  2010   \n4                   66.0       6     1155240.0     1860661.0  2016   \n\n                UPDATEDON   LATITUDE  LONGITUDE                       LOCATION  \n0  02/10/2018 03:50:01 PM  41.807441 -87.703956    (41.8074405, -87.703955849)  \n1  02/28/2018 03:56:25 PM  41.898280 -87.716406  (41.898279962, -87.716405505)  \n2  02/10/2018 03:50:01 PM  41.815933 -87.624642  (41.815933131, -87.624642127)  \n3  02/10/2018 03:50:01 PM  41.743665 -87.562463  (41.743665322, -87.562462756)  \n4  02/10/2018 03:50:01 PM  41.773455 -87.706480  (41.773455295, -87.706480471)  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>CASE_NUMBER</th>\n      <th>DATE</th>\n      <th>BLOCK</th>\n      <th>IUCR</th>\n      <th>PRIMARY_TYPE</th>\n      <th>DESCRIPTION</th>\n      <th>LOCATION_DESCRIPTION</th>\n      <th>ARREST</th>\n      <th>DOMESTIC</th>\n      <th>BEAT</th>\n      <th>DISTRICT</th>\n      <th>WARD</th>\n      <th>COMMUNITY_AREA_NUMBER</th>\n      <th>FBICODE</th>\n      <th>X_COORDINATE</th>\n      <th>Y_COORDINATE</th>\n      <th>YEAR</th>\n      <th>UPDATEDON</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LOCATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3512276</td>\n      <td>HK587712</td>\n      <td>08/28/2004 05:50:56 PM</td>\n      <td>047XX S KEDZIE AVE</td>\n      <td>890</td>\n      <td>THEFT</td>\n      <td>FROM BUILDING</td>\n      <td>SMALL RETAIL STORE</td>\n      <td>False</td>\n      <td>False</td>\n      <td>911</td>\n      <td>9</td>\n      <td>14.0</td>\n      <td>58.0</td>\n      <td>6</td>\n      <td>1155838.0</td>\n      <td>1873050.0</td>\n      <td>2004</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.807441</td>\n      <td>-87.703956</td>\n      <td>(41.8074405, -87.703955849)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3406613</td>\n      <td>HK456306</td>\n      <td>06/26/2004 12:40:00 PM</td>\n      <td>009XX N CENTRAL PARK AVE</td>\n      <td>820</td>\n      <td>THEFT</td>\n      <td>$500 AND UNDER</td>\n      <td>OTHER</td>\n      <td>False</td>\n      <td>False</td>\n      <td>1112</td>\n      <td>11</td>\n      <td>27.0</td>\n      <td>23.0</td>\n      <td>6</td>\n      <td>1152206.0</td>\n      <td>1906127.0</td>\n      <td>2004</td>\n      <td>02/28/2018 03:56:25 PM</td>\n      <td>41.898280</td>\n      <td>-87.716406</td>\n      <td>(41.898279962, -87.716405505)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8002131</td>\n      <td>HT233595</td>\n      <td>04/04/2011 05:45:00 AM</td>\n      <td>043XX S WABASH AVE</td>\n      <td>820</td>\n      <td>THEFT</td>\n      <td>$500 AND UNDER</td>\n      <td>NURSING HOME/RETIREMENT HOME</td>\n      <td>False</td>\n      <td>False</td>\n      <td>221</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>38.0</td>\n      <td>6</td>\n      <td>1177436.0</td>\n      <td>1876313.0</td>\n      <td>2011</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.815933</td>\n      <td>-87.624642</td>\n      <td>(41.815933131, -87.624642127)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7903289</td>\n      <td>HT133522</td>\n      <td>12/30/2010 04:30:00 PM</td>\n      <td>083XX S KINGSTON AVE</td>\n      <td>840</td>\n      <td>THEFT</td>\n      <td>FINANCIAL ID THEFT: OVER $300</td>\n      <td>RESIDENCE</td>\n      <td>False</td>\n      <td>False</td>\n      <td>423</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>46.0</td>\n      <td>6</td>\n      <td>1194622.0</td>\n      <td>1850125.0</td>\n      <td>2010</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.743665</td>\n      <td>-87.562463</td>\n      <td>(41.743665322, -87.562462756)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10402076</td>\n      <td>HZ138551</td>\n      <td>02/02/2016 07:30:00 PM</td>\n      <td>033XX W 66TH ST</td>\n      <td>820</td>\n      <td>THEFT</td>\n      <td>$500 AND UNDER</td>\n      <td>ALLEY</td>\n      <td>False</td>\n      <td>False</td>\n      <td>831</td>\n      <td>8</td>\n      <td>15.0</td>\n      <td>66.0</td>\n      <td>6</td>\n      <td>1155240.0</td>\n      <td>1860661.0</td>\n      <td>2016</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.773455</td>\n      <td>-87.706480</td>\n      <td>(41.773455295, -87.706480471)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df.tail()", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "           ID CASE_NUMBER                    DATE                BLOCK  IUCR  \\\n528  10453948    HZ192829  03/01/2016 12:00:00 AM      028XX E 79TH ST  1055   \n529  10397129    HZ133234  01/29/2016 03:30:00 PM  006XX W HARRISON ST  5114   \n530   3269495    HJ747227  11/08/2003 04:54:15 PM      012XX W 81ST ST   510   \n531  10840565    JA143710  02/06/2017 01:20:00 PM   009XX N KARLOV AVE  5073   \n532   1326195     G021609  01/11/2001 02:30:41 AM  087XX S ESCANABA AV  9901   \n\n                         PRIMARY_TYPE  \\\n528                 HUMAN TRAFFICKING   \n529                    NON - CRIMINAL   \n530                         RITUALISM   \n531  NON-CRIMINAL (SUBJECT SPECIFIED)   \n532                 DOMESTIC VIOLENCE   \n\n                                     DESCRIPTION LOCATION_DESCRIPTION  ARREST  \\\n528                        INVOLUNTARY SERVITUDE            APARTMENT   False   \n529                            FOID - REVOCATION               STREET   False   \n530  AGG RIT MUT: HANDS/FIST/FEET SERIOUS INJURY                OTHER   False   \n531       NOTIFICATION OF CIVIL NO CONTACT ORDER            RESIDENCE   False   \n532                            DOMESTIC VIOLENCE            APARTMENT    True   \n\n     DOMESTIC  BEAT  DISTRICT  WARD  COMMUNITY_AREA_NUMBER FBICODE  \\\n528     False   422         4   7.0                   46.0      26   \n529     False   124         1   2.0                   28.0      26   \n530     False   612         6  21.0                   71.0     04B   \n531      True  1111        11  37.0                   23.0      26   \n532      True   423         4   NaN                    NaN     08B   \n\n     X_COORDINATE  Y_COORDINATE  YEAR               UPDATEDON   LATITUDE  \\\n528     1196679.0     1853139.0  2016  02/10/2018 03:50:01 PM  41.751885   \n529     1172257.0     1897564.0  2016  02/10/2018 03:50:01 PM  41.874363   \n530     1169648.0     1851076.0  2003  02/28/2018 03:56:25 PM  41.746852   \n531     1148881.0     1905963.0  2017  02/14/2017 03:49:42 PM  41.897895   \n532     1196869.0     1847416.0  2001  08/17/2015 03:03:40 PM  41.736176   \n\n     LONGITUDE                       LOCATION  \n528 -87.554826  (41.751885152, -87.554825997)  \n529 -87.643013  (41.874363279, -87.643013039)  \n530 -87.653941  (41.746852486, -87.653941385)  \n531 -87.728622   (41.89789489, -87.728622316)  \n532 -87.554320   (41.73617608, -87.554319607)  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>CASE_NUMBER</th>\n      <th>DATE</th>\n      <th>BLOCK</th>\n      <th>IUCR</th>\n      <th>PRIMARY_TYPE</th>\n      <th>DESCRIPTION</th>\n      <th>LOCATION_DESCRIPTION</th>\n      <th>ARREST</th>\n      <th>DOMESTIC</th>\n      <th>BEAT</th>\n      <th>DISTRICT</th>\n      <th>WARD</th>\n      <th>COMMUNITY_AREA_NUMBER</th>\n      <th>FBICODE</th>\n      <th>X_COORDINATE</th>\n      <th>Y_COORDINATE</th>\n      <th>YEAR</th>\n      <th>UPDATEDON</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>LOCATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>528</th>\n      <td>10453948</td>\n      <td>HZ192829</td>\n      <td>03/01/2016 12:00:00 AM</td>\n      <td>028XX E 79TH ST</td>\n      <td>1055</td>\n      <td>HUMAN TRAFFICKING</td>\n      <td>INVOLUNTARY SERVITUDE</td>\n      <td>APARTMENT</td>\n      <td>False</td>\n      <td>False</td>\n      <td>422</td>\n      <td>4</td>\n      <td>7.0</td>\n      <td>46.0</td>\n      <td>26</td>\n      <td>1196679.0</td>\n      <td>1853139.0</td>\n      <td>2016</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.751885</td>\n      <td>-87.554826</td>\n      <td>(41.751885152, -87.554825997)</td>\n    </tr>\n    <tr>\n      <th>529</th>\n      <td>10397129</td>\n      <td>HZ133234</td>\n      <td>01/29/2016 03:30:00 PM</td>\n      <td>006XX W HARRISON ST</td>\n      <td>5114</td>\n      <td>NON - CRIMINAL</td>\n      <td>FOID - REVOCATION</td>\n      <td>STREET</td>\n      <td>False</td>\n      <td>False</td>\n      <td>124</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>28.0</td>\n      <td>26</td>\n      <td>1172257.0</td>\n      <td>1897564.0</td>\n      <td>2016</td>\n      <td>02/10/2018 03:50:01 PM</td>\n      <td>41.874363</td>\n      <td>-87.643013</td>\n      <td>(41.874363279, -87.643013039)</td>\n    </tr>\n    <tr>\n      <th>530</th>\n      <td>3269495</td>\n      <td>HJ747227</td>\n      <td>11/08/2003 04:54:15 PM</td>\n      <td>012XX W 81ST ST</td>\n      <td>510</td>\n      <td>RITUALISM</td>\n      <td>AGG RIT MUT: HANDS/FIST/FEET SERIOUS INJURY</td>\n      <td>OTHER</td>\n      <td>False</td>\n      <td>False</td>\n      <td>612</td>\n      <td>6</td>\n      <td>21.0</td>\n      <td>71.0</td>\n      <td>04B</td>\n      <td>1169648.0</td>\n      <td>1851076.0</td>\n      <td>2003</td>\n      <td>02/28/2018 03:56:25 PM</td>\n      <td>41.746852</td>\n      <td>-87.653941</td>\n      <td>(41.746852486, -87.653941385)</td>\n    </tr>\n    <tr>\n      <th>531</th>\n      <td>10840565</td>\n      <td>JA143710</td>\n      <td>02/06/2017 01:20:00 PM</td>\n      <td>009XX N KARLOV AVE</td>\n      <td>5073</td>\n      <td>NON-CRIMINAL (SUBJECT SPECIFIED)</td>\n      <td>NOTIFICATION OF CIVIL NO CONTACT ORDER</td>\n      <td>RESIDENCE</td>\n      <td>False</td>\n      <td>True</td>\n      <td>1111</td>\n      <td>11</td>\n      <td>37.0</td>\n      <td>23.0</td>\n      <td>26</td>\n      <td>1148881.0</td>\n      <td>1905963.0</td>\n      <td>2017</td>\n      <td>02/14/2017 03:49:42 PM</td>\n      <td>41.897895</td>\n      <td>-87.728622</td>\n      <td>(41.89789489, -87.728622316)</td>\n    </tr>\n    <tr>\n      <th>532</th>\n      <td>1326195</td>\n      <td>G021609</td>\n      <td>01/11/2001 02:30:41 AM</td>\n      <td>087XX S ESCANABA AV</td>\n      <td>9901</td>\n      <td>DOMESTIC VIOLENCE</td>\n      <td>DOMESTIC VIOLENCE</td>\n      <td>APARTMENT</td>\n      <td>True</td>\n      <td>True</td>\n      <td>423</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>08B</td>\n      <td>1196869.0</td>\n      <td>1847416.0</td>\n      <td>2001</td>\n      <td>08/17/2015 03:03:40 PM</td>\n      <td>41.736176</td>\n      <td>-87.554320</td>\n      <td>(41.73617608, -87.554319607)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Clean up the data and prepare\n\nNow that the data has been imported it needs to be cleaned.\n\n1. Move September 2017 dates to September 2018\n2. Clean up the column names:\n    A. Strip leading & trailing whitespace\n    B. Replace multiple spaces with a single space\n    C. Remove # characters\n    D. Replace spaces with _\n    E. Convert to lowercase\n3. Change the date of occurance field to a date / time object\n4. Add new columns for:\n    A. Hour\n    B. Day\n    C. Month\n    D. Year\n    etc.\n5. Split Block into zip_code and street\n6. Verify that all rows have valid data"}, {"metadata": {}, "cell_type": "code", "source": "df.columns = df.columns.str.strip()\ndf.columns = df.columns.str.replace('\\s{2,}', ' ')\ndf.columns = df.columns.str.replace('#', '')\ndf.columns = df.columns.str.replace(' ', '_')\ndf.columns = df.columns.str.lower()\ndf.date.replace(to_replace=\"(09/\\\\d+)/2017\", value=r\"\\1/2018\", regex=True, inplace=True)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.dtypes", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "id                         int64\ncase_number               object\ndate                      object\nblock                     object\niucr                      object\nprimary_type              object\ndescription               object\nlocation_description      object\narrest                      bool\ndomestic                    bool\nbeat                       int64\ndistrict                   int64\nward                     float64\ncommunity_area_number    float64\nfbicode                   object\nx_coordinate             float64\ny_coordinate             float64\nyear                       int64\nupdatedon                 object\nlatitude                 float64\nlongitude                float64\nlocation                  object\ndtype: object"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Change the date of occurance field to a date / time object"}, {"metadata": {}, "cell_type": "code", "source": "df['date'] =  pd.to_datetime(df['date'], format='%m/%d/%Y %I:%M:%S %p')", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Add new columns for the hour, day, month and year of the crime:\n\n* Hour\n* Day Name\n* Day of week (Tuesday is the first day)\n* Month Name\n* Month Number\n* Year\n* Year and Month"}, {"metadata": {}, "cell_type": "code", "source": "df['hour'] = df['date'].dt.hour\ndf['day_name'] = df['date'].dt.day_name()\ndf['day'] = df['date'].dt.dayofweek + 1\ndf['month_name'] = df['date'].dt.month_name()\ndf['month'] = df['date'].dt.month\ndf['year'] = df['date'].dt.year\ndf['year_month'] = df['date'].dt.to_period('M')", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Split Block into zip_code and street"}, {"metadata": {}, "cell_type": "code", "source": "df['zip'] = df.block.str.split(' ').str[0]\ndf['street'] = df.block.str.split(' ').str[1:].apply(', '.join)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Verify that all rows have valid data"}, {"metadata": {}, "cell_type": "code", "source": "df.isna().sum()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The data is now ready for visualisation."}, {"metadata": {}, "cell_type": "code", "source": "df.dropna(inplace=True)\ndf.reindex()\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Data Visualisation\nTo get a better understanding of the data we will now visualise it.\n### Number of Crimes per Year"}, {"metadata": {}, "cell_type": "code", "source": "df.groupby('year').count().plot(y = 'case_number', \n                                      kind='bar',\n                                      figsize=(10,6),\n                                      width=0.85,\n                                      fontsize=12,\n                                      colormap='tab20').legend(bbox_to_anchor=(1,1),\n                                                               prop={'size': 12})\n\nplt.xlabel('Year')\nplt.ylabel('Number of Cases')\nplt.title('Number of Cases Per Year', loc='left', fontsize=18)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Unsuprisingly there little obvious variation in the number of crimes committed per month other than an apparent drop-off in February.\n## Number of crimes occuring on each day"}, {"metadata": {}, "cell_type": "code", "source": "df.groupby('day').count().plot(y = 'case_number',\n                               kind='bar',\n                               figsize=(10,6),\n                               width=0.85,\n                               fontsize=12,\n                               colormap='tab20').legend(bbox_to_anchor=(1,1),\n                                                        prop={'size': 12})\n\nplt.xlabel('Day of Week')\nplt.ylabel('Count of Cases per Day')\nplt.title('Count of Cases Per Day of Week [1 is a Monday]', loc='left', fontsize=18)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "There is a small increase in crime reported at the weekend, Saturday and Sunday, but nothing that couldbe considered significant.\n## Number of crimes occuring in each hour"}, {"metadata": {}, "cell_type": "code", "source": "df.groupby('hour').count().plot(y = 'case_number',\n                               kind='bar',\n                               figsize=(10,6),\n                               width=0.85,\n                               fontsize=12,\n                               colormap='tab20').legend(bbox_to_anchor=(1,1),\n                                                        prop={'size': 12})\n\nplt.xlabel('Hour of Day')\nplt.ylabel('Count of Cases per Hour')\nplt.title('Count of Cases Per Hour]', loc='left', fontsize=18)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "There is an expected fall-off in reported crime rates after midnight before elevating again after eight in the morning.\n\nNow let's look at the Crime Categories."}, {"metadata": {}, "cell_type": "code", "source": "# Number of unique Crime categories bases on the Primary Description\ndf.primary_type.nunique()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# What Crimes are the 3 most commonly occuring ones \ndf[['primary_type', 'case_number']].groupby(\n    ['primary_type'], as_index=False).count().sort_values(\n    'case_number', ascending=False).head(3)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create a list of the 10 most commonly occuring crimes\ntop_crimes = df[['primary_type', 'case_number']].groupby(\n    ['primary_type']).count().sort_values('case_number', ascending=False)[:10].axes[0].tolist()\n\n# Create a list of the 3 most commonly occuring crimes\ntop_three_crimes = df[['primary_type', 'case_number']].groupby(\n    ['primary_type']).count().sort_values('case_number', ascending=False)[:3].axes[0].tolist()\n\n# Create a list of the 2 most commonly occuring crimes\ntop_two_crimes = df[['primary_type', 'case_number']].groupby(\n    ['primary_type']).count().sort_values('case_number', ascending=False)[:2].axes[0].tolist()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Create a new data frame with just the top 10 crimes\ndf_top_crimes = df[df['primary_type'].isin(top_crimes)].copy()\n\n# Create a new data frame with just the top 10 crimes\ndf_top3_crimes = df[df['primary_type'].isin(top_three_crimes)].copy()\n\ndf_top3_crimes[['case_number', 'primary_type', 'year']].pivot_table(\n    index='year', \n    columns='primary_type', \n    fill_value=0, \n    aggfunc='count').plot(kind='area',\n                          stacked=True,\n                          figsize=(15, 6),\n                               fontsize=12,\n                               colormap='tab20')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_top3_crimes[['case_number', 'primary_type', 'hour']].pivot_table(\n    index='hour', \n    columns='primary_type', \n    fill_value=0, \n    aggfunc='count').plot(kind='area',\n                          stacked=True,\n                          figsize=(15, 6),\n                               fontsize=12,\n                               colormap='tab20')\n\nplt.xlabel('Hour of Day')\nplt.ylabel('Count of Cases per Hour')\nplt.title('Count of Cases Per Hour]', loc='left', fontsize=18)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Visual Crimes on map of Chicago"}, {"metadata": {}, "cell_type": "code", "source": "df_top_crimes.dtypes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Create a folium map with a different colour per crime\nColour each of the top 10 crimes with a different and plot on a Folium map."}, {"metadata": {}, "cell_type": "code", "source": "# Create a list of colours. \n# We have  list of the top 10 crimes from earlier\ncolors = [\n    'red',\n    'blue',\n    'gray',\n    'orange',\n    'beige',\n    'green',\n    'purple',\n    'pink',\n    'cadetblue',\n    'black'\n]\n\n# Create a dictionary of colours to map to the crimes\ndict_colours = dict(zip(top_crimes, colors))\n\n# Add the colours colums to the df_top_crimes DataFrame\ndf_top_crimes['colour'] = df_top_crimes.primary_type.map(dict_colours)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The entire df_top_crimes DataFrame contains too many point to disply effeciently using Folium. To combat this we will just use the data from August."}, {"metadata": {}, "cell_type": "code", "source": "df_top_crimes_august = df_top_crimes[df_top_crimes.month_name == 'August']\n\n# Pickle the DataFrame to Separate the Folium Maps into a Separate Notepad\ndf_top_crimes_august.to_pickle('crimes_august.pkl')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "chicago_latitude = 41.85  \nchicago_longitude = -87.75\nmc = MarkerCluster()\n\n# Define the world map centered around Chicago with a higher zoom level\nchicago_cluster = folium.Map(location=[chicago_latitude, chicago_longitude], zoom_start=11)\n\n# display world map\nchicago_cluster\n\n#creating a Marker for each point in df_sample. Each point will get a popup with their zip\nfor row in df_top_crimes_august.itertuples():\n    mc.add_child(folium.Marker(\n        location=[row.latitude,  row.longitude],\n                 popup=row.primary_type))\n\nchicago_cluster.add_child(mc)\nchicago_cluster", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nfrom folium import plugins\nfrom folium.plugins import HeatMap\n\nchicago_heatmat = folium.Map(location=[chicago_latitude, chicago_longitude], zoom_start=11) \n\n# List comprehension to make out list of lists\nheat_data = [[row['latitude'], \n              row['longitude']] for index, row in df_top_crimes_august.iterrows()]\n\n# Plot it on the map\nHeatMap(heat_data,\n        min_opacity=0.5,\n        max_zoom=18, \n        max_val=1.0, \n        radius=15,\n        blur=20,\n        gradient=None,\n        overlay=True).add_to(chicago_heatmat)\n\n# Display the map\nchicago_heatmat", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_top_crimes.dtypes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Data Preparation for Modelling\nBefore we start modelling we need to prepare the data frame to include only mumerical data and by removing unneeded columns.\n\nRather than removing colums from df_top_crimes a new df_features DataFrame will be created with just the required columns. This df_features DataFrame will then be processed to remove Categorical Data Types and replace them with One Hot encoding. Finally the Dependant Variables will be Normalised and Principal Component Analysis will be used to reduce the dimensionality of the DataFrame."}, {"metadata": {}, "cell_type": "code", "source": "# Start by copying the Latitude and Longitude to the new DataFrame\ndf_features = df_top_crimes[['latitude', 'longitude']]\n\n# Next and One Hot Encoding of the hour, day and month variables\ndf_features = df_features.join(pd.get_dummies(df_top_crimes.hour, prefix='hour'))\ndf_features = df_features.join(pd.get_dummies(df_top_crimes.day_name))\ndf_features = df_features.join(pd.get_dummies(df_top_crimes.month_name))\n\n# Finally add the ward & crimes column, copied from the original Primary Description column\ndf_features['ward'] = df_top_crimes[['ward']]\ndf_features['crimes'] = df_top_crimes[['primary_type']]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_features.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "There are a couple of further small changes to be made:\n\n* Create a smaller DataFrame of only the top three crimes\n* Create the X, dependant variables, DataFrames by dropping the Crimes column\n* Create the y, independant variable,\n* Normailse the X Data"}, {"metadata": {}, "cell_type": "code", "source": "# Create a smaller DataFrame of only the top three crimes\ndf_features_3 = df_features[df_features['crimes'].isin(top_three_crimes)].copy()\n\n# Create a smaller DataFrame of only the top two crimes\ndf_features_2 = df_features[df_features['crimes'].isin(top_two_crimes)].copy()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#  Create the X, dependant variables, DataFrames by dropping the Crimes column\nX_10 = df_features.copy()\ny_10 = X_10.crimes.values\n\nX_10.drop('crimes', axis=1, inplace=True)\nX_10 = preprocessing.StandardScaler().fit(X_10).transform(X_10)\n\n\nX_3 = df_features_3.copy()\ny_3 = X_3.crimes.values\n\nX_3.drop('crimes', axis=1, inplace=True)\nX_3 = preprocessing.StandardScaler().fit(X_3).transform(X_3)\n\nX_2 = df_features_2.copy()\ny_2 = X_2.crimes.values\n\nX_2.drop('crimes', axis=1, inplace=True)\nX_2 = preprocessing.StandardScaler().fit(X_2).transform(X_2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Set X = X_10\nX = X_10\ny = y_10", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Set X = X_3\nX = X_3\ny = y_3", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Set X = X_2\nX = X_2\ny = y_2", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## K Nearest Neighbor(KNN)\nFind the best k to build the model with the best accuracy."}, {"metadata": {}, "cell_type": "code", "source": "# Decision Tree\nfrom datetime import datetime\nfrom sklearn.tree import DecisionTreeClassifier\n\ndepths = range(10, 16)\nscores = np.zeros((len(depths), 3))\n# scores = np.zeros((len(depths), 2))\nfor idx, depth in enumerate(depths):\n    print('Depth: ', depth, ' ', str(datetime.now()))\n    model = DecisionTreeClassifier(criterion = \"entropy\", max_depth = depth)\n    scores[idx, : ] = cross_validate(model, n_splits = 10)\n\nplt.plot(depths, scores[ : , 1], 'b')\nplt.fill_between(depths, scores[ : , 0], scores[:, 2], alpha = 0.1)\nplt.legend(('Median', '(40, 60) percentile'))\nplt.ylabel('Accuracy')\nplt.xlabel('Depth')\nplt.tight_layout()\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nC = np.logspace(-2.0, 0.5, num = 6, endpoint = True)\nscores = np.zeros((len(C), 3))\nfor idx, c in enumerate(C):\n    print('C: ', c, ' ', str(datetime.now()))\n    model = LogisticRegression(C = c, solver = 'liblinear')\n    scores[idx, : ] = cross_validate(model, n_splits = 10)\n\nplt.plot(C, scores[ : , 1], 'b')\nplt.xscale('log')\nplt.fill_between(C, scores[ : , 0], scores[:, 2], alpha = 0.1)\nplt.legend(('Median', '(40, 60) percentile'))\nplt.ylabel('Accuracy')\nplt.xlabel('C')\nplt.tight_layout()\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Naive Bayes\n\nalpha = np.linspace(0.1, 1, num=10)\nscores = np.zeros((len(alpha), 3))\nfor idx, a in enumerate(alpha):\n    print('Alpha: ', a, ' ', str(datetime.now()))\n    model = BernoulliNB()\n    scores[idx, : ] = cross_validate(model, n_splits = 10)\n\nplt.plot(alpha, scores[ : , 1], 'b')\nplt.xscale('log')\nplt.fill_between(alpha, scores[ : , 0], scores[:, 2], alpha = 0.1)\nplt.legend(('Median', '(40, 60) percentile'))\nplt.ylabel('Accuracy')\nplt.xlabel('C')\nplt.tight_layout()\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Decision Forest using a Random Forest\n\nest = range(12, 18)\nscores = np.zeros((len(est), 3))\nfor idx, a in enumerate(est):\n    print('Estimator: ', a, ' ', str(datetime.now()))\n    model = RandomForestClassifier(n_estimators = a, max_features = 'sqrt')\n    scores[idx, : ] = cross_validate(model, n_splits = 10)\n\nplt.plot(est, scores[ : , 1], 'b')\nplt.fill_between(est, scores[ : , 0], scores[:, 2], alpha = 0.1)\nplt.legend(('Median', '(40, 60) percentile'))\nplt.ylabel('Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.tight_layout()\nplt.show()", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}